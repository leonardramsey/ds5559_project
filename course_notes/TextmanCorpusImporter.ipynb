{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wso0f_Smc4ee"
   },
   "source": [
    "# Synpsis\n",
    "\n",
    "Use case: Import source text and save in F3 form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEDIrQRJc-nn"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "477MrZfFc9oh"
   },
   "outputs": [],
   "source": [
    "body_start = 341\n",
    "body_end = 21964\n",
    "chap_pat = r'^\\s*(?:CHAPTER|ETYMOLOGY|Epilogue).*$'\n",
    "para_pat = r'\\n\\n+'\n",
    "sent_pat = r'([.;?!\"“”]+)'\n",
    "token_pat = r'([\\W_]+)'\n",
    "db_file = 'moby.db'\n",
    "src_file_name = '2701-0.txt'\n",
    "src_file_url = 'https://www.gutenberg.org/files/2701/2701-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "477MrZfFc9oh"
   },
   "outputs": [],
   "source": [
    "extra_stopwords = \"\"\"\n",
    "us rest went least would much must long one like much say well without though yet might still upon\n",
    "done every rather particular made many previous always never thy thou go first oh thee ere ye came\n",
    "almost could may sometimes seem called among another also however nevertheless even way one two three\n",
    "ever put\n",
    "\"\"\".strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "477MrZfFc9oh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'almost',\n",
       " 'also',\n",
       " 'always',\n",
       " 'among',\n",
       " 'another',\n",
       " 'called',\n",
       " 'came',\n",
       " 'could',\n",
       " 'done',\n",
       " 'ere',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'first',\n",
       " 'go',\n",
       " 'however',\n",
       " 'least',\n",
       " 'like',\n",
       " 'long',\n",
       " 'made',\n",
       " 'many',\n",
       " 'may',\n",
       " 'might',\n",
       " 'much',\n",
       " 'must',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'oh',\n",
       " 'one',\n",
       " 'particular',\n",
       " 'previous',\n",
       " 'put',\n",
       " 'rather',\n",
       " 'rest',\n",
       " 'say',\n",
       " 'seem',\n",
       " 'sometimes',\n",
       " 'still',\n",
       " 'thee',\n",
       " 'thou',\n",
       " 'though',\n",
       " 'three',\n",
       " 'thy',\n",
       " 'two',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'way',\n",
       " 'well',\n",
       " 'went',\n",
       " 'without',\n",
       " 'would',\n",
       " 'ye',\n",
       " 'yet'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(extra_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "JkFioCMVW8pl"
   },
   "outputs": [],
   "source": [
    "OHCO = ['chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "CHAPS = OHCO[:1]\n",
    "PARAS = OHCO[:2]\n",
    "SENTS = OHCO[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A58rgKXydL8y"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8617,
     "status": "ok",
     "timestamp": 1550542848134,
     "user": {
      "displayName": "Rafael Alvarado",
      "photoUrl": "https://lh3.googleusercontent.com/-gvKWs7zR4JY/AAAAAAAAAAI/AAAAAAABqfk/Q8O12g6M_T4/s64/photo.jpg",
      "userId": "11010075019714369526"
     },
     "user_tz": 300
    },
    "id": "YbadDvzWW0Sw",
    "outputId": "53c6fd6b-67cf-47cd-e43c-e46a8a334340"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/leonardramsey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/leonardramsey/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leonardramsey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/leonardramsey/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/leonardramsey/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC-m8q8Hd1dq"
   },
   "source": [
    "# Pragmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC-m8q8Hd1dq"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AwIc1D23UuOQ"
   },
   "source": [
    "# Process\n",
    "\n",
    "We pause to look at the revised form of our text import function. The parsing function has been replaced with NLTK, which has improved the results of POS tagging. However, this has required some added string manipulation to produce better tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHUyjB23sUTc"
   },
   "source": [
    "## Download if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHUyjB23sUTc"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(src_file_name):\n",
    "  import requests\n",
    "  with open(src_file_name, 'w', encoding='utf-8') as src_file_on_disk:\n",
    "    src_file_url = src_file_url\n",
    "    src_file_text = requests.get(src_file_url).text\n",
    "    src_file_on_disk.write(src_file_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "source": [
    "## Text to lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oxgp19ejZmU"
   },
   "outputs": [],
   "source": [
    "lines = open(src_file_name, 'r', encoding='utf-8').readlines()\n",
    "lines = lines[body_start - 1 : body_end + 1]\n",
    "df = pd.DataFrame({'line_str':lines})\n",
    "df.index.name = 'line_id'\n",
    "del(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScU67cbRdqoE"
   },
   "source": [
    "## Fix some characters to improve tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScU67cbRdqoE"
   },
   "outputs": [],
   "source": [
    "df.line_str = df.line_str.str.replace('—', ' — ')\n",
    "df.line_str = df.line_str.str.replace('-', ' - ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_raVDc5dsa4"
   },
   "source": [
    "## Lines to Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_raVDc5dsa4"
   },
   "outputs": [],
   "source": [
    "chap_mask = df.line_str.str.match(chap_pat)\n",
    "df.loc[chap_mask, 'chap_id'] = df.apply(lambda x: x.name, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZD56huvGCzE"
   },
   "outputs": [],
   "source": [
    "df.chap_id = df.chap_id.ffill().astype('int')\n",
    "chap_ids = df.chap_id.unique().tolist()\n",
    "df['chap_num'] = df.chap_id.apply(lambda x: chap_ids.index(x))\n",
    "chaps = df.groupby('chap_num')\\\n",
    "    .apply(lambda x: ''.join(x.line_str))\\\n",
    "    .to_frame()\\\n",
    "    .rename(columns={0:'chap_str'})\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcffE_kleR0f"
   },
   "source": [
    "## Chapters to Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcffE_kleR0f"
   },
   "outputs": [],
   "source": [
    "paras = chaps.chap_str.str.split(para_pat, expand=True)\\\n",
    "    .stack()\\\n",
    "    .to_frame()\\\n",
    "    .rename(columns={0:'para_str'})\n",
    "paras.index.names = PARAS\n",
    "paras.para_str = paras.para_str.str.strip()\n",
    "paras.para_str = paras.para_str.str.replace(r'\\n', ' ')\n",
    "paras.para_str = paras.para_str.str.replace(r'\\s+', ' ')\n",
    "paras = paras[~paras.para_str.str.match(r'^\\s*$')]\n",
    "del(chaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATUd7_HdeXk5"
   },
   "source": [
    "## Paragraphs to Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATUd7_HdeXk5"
   },
   "outputs": [],
   "source": [
    "#     sents = paras.para_str.str.split(sent_pat, expand=True)\\\n",
    "sents = paras.para_str\\\n",
    "    .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "    .stack()\\\n",
    "    .to_frame()\\\n",
    "    .rename(columns={0:'sent_str'})\n",
    "sents.index.names = SENTS\n",
    "del(paras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JglgExtWeaqN"
   },
   "source": [
    "## Sentences to Tokens with POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JglgExtWeaqN"
   },
   "outputs": [],
   "source": [
    "#     tokens = sents.sent_str.str.split(token_pat, expand=True)\\\n",
    "tokens = sents.sent_str\\\n",
    "    .apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x))))\\\n",
    "    .stack()\\\n",
    "    .to_frame()\\\n",
    "    .rename(columns={0:'pos_tuple'})\n",
    "tokens.index.names = OHCO\n",
    "tokens['pos'] = tokens.pos_tuple.apply(lambda x: x[1])\n",
    "tokens['token_str'] = tokens.pos_tuple.apply(lambda x: x[0])\n",
    "tokens = tokens.drop('pos_tuple', 1)\n",
    "del(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZT8DGE7ek4F"
   },
   "source": [
    "## Tag punctuation and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZT8DGE7ek4F"
   },
   "outputs": [],
   "source": [
    "tokens['punc'] = tokens.token_str.str.match(r'^[\\W_]*$').astype('int')\n",
    "tokens['num'] = tokens.token_str.str.match(r'^.*\\d.*$').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH2pV_ABrkmB"
   },
   "source": [
    "## Extract vocab with minimal normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH2pV_ABrkmB"
   },
   "outputs": [],
   "source": [
    "WORDS = (tokens.punc == 0) & (tokens.num == 0)\n",
    "tokens.loc[WORDS, 'term_str'] = tokens.token_str.str.lower()\\\n",
    "    .str.replace(r'[\"_*.]', '')\n",
    "vocab = tokens[tokens.punc == 0].term_str.value_counts().to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'index':'term_str', 'term_str':'n'})\n",
    "vocab = vocab.sort_values('term_str').reset_index(drop=True)\n",
    "vocab.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKyrqpzfr7Le"
   },
   "source": [
    "## Get priors for Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKyrqpzfr7Le"
   },
   "outputs": [],
   "source": [
    "vocab['p'] = vocab.n / vocab.n.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9L8f3mBr8vW"
   },
   "source": [
    "## Add stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9L8f3mBr8vW"
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "vocab['port_stem'] = vocab.term_str.apply(lambda x: stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6Lyvd5Qr93-"
   },
   "source": [
    "## Define stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6Lyvd5Qr93-"
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english') + extra_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6Lyvd5Qr93-"
   },
   "outputs": [],
   "source": [
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6Lyvd5Qr93-"
   },
   "outputs": [],
   "source": [
    "sw = pd.DataFrame({'x':1}, index=stopwords)\n",
    "vocab['stop'] = vocab.term_str.map(sw.x).fillna(0).astype('int')\n",
    "del(sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WxRILKRNr-7C"
   },
   "source": [
    "## Add term_ids to Tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WxRILKRNr-7C"
   },
   "outputs": [],
   "source": [
    "tokens['term_id'] = tokens['term_str'].map(vocab.reset_index()\\\n",
    "    .set_index('term_str').term_id).fillna(-1).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTWfAutZKuRP"
   },
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLQ1KGZCsMFx"
   },
   "outputs": [],
   "source": [
    "with sqlite3.connect(db_file) as db:\n",
    "    tokens.to_sql('token', db, if_exists='replace', index=True)\n",
    "    vocab.to_sql('vocab', db, if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4q1kGXJuLDSp"
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TextmanCorpusImporter.ipynb",
   "provenance": [
    {
     "file_id": "1UJXtZFtWykmkbZSLyLxpKmwiGhXr1w6P",
     "timestamp": 1550255827012
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
